# LocalRAG â€” Chatbot RAG AvancÃ© avec Streamlit

Application de chat conversationnel **style ChatGPT** construite avec Streamlit et l'API OpenAI, enrichie d'un pipeline de **Retrieval-Augmented Generation (RAG)** performant. Indexez vos propres documents et obtenez des rÃ©ponses contextualisÃ©es en quelques clics.

ğŸ”— **DÃ©mo en ligne** : [laposte-57sgwe24hqzegfthseuprg.streamlit.app](https://laposte-57sgwe24hqzegfthseuprg.streamlit.app/)

---

## âœ¨ FonctionnalitÃ©s ClÃ©s

| CatÃ©gorie | Description |
|-----------|-------------|
| **Chat Intelligent** | Interface conversationnelle fluide avec streaming des rÃ©ponses en temps rÃ©el |
| **RAG AvancÃ©** | Indexation vectorielle FAISS, embeddings OpenAI `text-embedding-3-large`, reranking cross-encoder |
| **Multi-formats** | Support CSV, TSV, XLSX, XLS, PDF, DOCX, TXT, MD, JSON (y compris NDJSON) |
| **Vision** | Prise en charge des images (GPT-5.1, GPT-5) pour analyse visuelle |
| **Mode QualitÃ©** | Multi-pass generation, MMR search (Î»=0.35), top-k=8, reranking automatique |
| **Session SÃ©curisÃ©e** | ClÃ© API saisie directement dans l'UI, donnÃ©es en mÃ©moire uniquement |

---

## ğŸ—ï¸ Architecture du Projet

```
LocalRAG/
â”œâ”€â”€ main.py               # Application Streamlit principale (~2450 lignes)
â”œâ”€â”€ rag_utils.py          # Ingestion de documents, chunking, embeddings
â”œâ”€â”€ config.py             # Configuration RAG (PerfConfig dataclass)
â”œâ”€â”€ adapters.py           # Conversion messages â†’ schÃ©ma OpenAI Chat/Responses
â”œâ”€â”€ token_utils.py        # Comptage et troncature de tokens
â”œâ”€â”€ image_utils.py        # Traitement d'images pour vision
â”œâ”€â”€ responses_schema.py   # SchÃ©mas de rÃ©ponses structurÃ©es
â”œâ”€â”€ rag/                  # Module RAG avancÃ©
â”‚   â”œâ”€â”€ pipeline.py       # Orchestration du pipeline RAG complet
â”‚   â”œâ”€â”€ retriever.py      # Logique de rÃ©cupÃ©ration et reranking
â”‚   â”œâ”€â”€ memory.py         # RÃ©sumÃ© de l'historique de conversation
â”‚   â””â”€â”€ prompts.py        # Templates de prompts systÃ¨me
â”œâ”€â”€ utils/                # Utilitaires
â”‚   â”œâ”€â”€ rendering.py      # Rendu et formatage
â”‚   â””â”€â”€ text_normalize.py # Normalisation de texte
â”œâ”€â”€ quality/              # Modules d'amÃ©lioration de qualitÃ©
â”œâ”€â”€ tests/                # Tests unitaires
â”œâ”€â”€ .streamlit/           # Configuration Streamlit
â””â”€â”€ requirements.txt      # DÃ©pendances Python
```

---

## ğŸš€ Installation & DÃ©marrage

### PrÃ©requis

- Python 3.9+
- ClÃ© API OpenAI (avec accÃ¨s aux modÃ¨les GPT)

### Installation

```bash
# Cloner le repository
git clone https://github.com/votre-username/LocalRAG.git
cd LocalRAG

# CrÃ©er un environnement virtuel
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# ou .venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### Lancement

```bash
streamlit run main.py
```

L'application s'ouvre dans votre navigateur. Entrez votre clÃ© API OpenAI pour commencer.

---

## ğŸ“„ Workflow RAG

1. **Upload de documents** â€” Glissez-dÃ©posez jusqu'Ã  5 fichiers (20 Mo max par dÃ©faut) dans la sidebar
2. **Indexation automatique** â€” Chunking intelligent (~4000 caractÃ¨res, 400 overlap), crÃ©ation de l'index FAISS
3. **Recherche contextuelle** â€” MMR (Maximal Marginal Relevance) + reranking cross-encoder
4. **GÃ©nÃ©ration multi-pass** â€” PremiÃ¨re rÃ©ponse puis amÃ©lioration automatique
5. **RÃ©ponses sourcÃ©es** â€” Chaque rÃ©ponse cite ses sources avec numÃ©rotation

### Types de fichiers supportÃ©s

| Format | Extensions | ParticularitÃ©s |
|--------|------------|----------------|
| Texte | `.txt`, `.md` | Encodage auto-dÃ©tectÃ© |
| Tableur | `.csv`, `.tsv`, `.xlsx`, `.xls` | Parsing par feuilles/lignes |
| Document | `.pdf`, `.docx` | Extraction par pages |
| DonnÃ©es | `.json` | Support NDJSON et streaming |

---

## âš™ï¸ Configuration

### Variables d'environnement

| Variable | DÃ©faut | Description |
|----------|--------|-------------|
| `OPENAI_API_KEY` | â€” | ClÃ© API OpenAI (optionnel si saisi dans l'UI) |
| `MAX_FILE_MB` | `20` | Taille maximale par fichier (Mo) |
| `ALLOW_LARGE_FILES` | `true` | Traitement chunkÃ© des gros fichiers |
| `MAX_TOTAL_CHARS` | â€” | Limite totale de caractÃ¨res ingÃ©rÃ©s |
| `QUALITY_ESCALATION` | `1` | Active le mode qualitÃ© avancÃ© (0 pour dÃ©sactiver) |

### Configuration RAG (`config.py`)

```python
@dataclass(frozen=True)
class PerfConfig:
    default_model: str = "gpt-5.1"
    rag_k: int = 8                 # Nombre de chunks rÃ©cupÃ©rÃ©s
    use_mmr: bool = True           # Maximal Marginal Relevance
    mmr_fetch_k: int = 40          # Taille du pool de candidats MMR
    mmr_lambda: float = 0.35       # Balance pertinence/diversitÃ©
    use_reranker: bool = True      # Cross-encoder reranking
    use_multipass: bool = True     # GÃ©nÃ©ration en 2 passes
    temperature: float = 0.3
    max_tokens: int = 2000
```

---

## ğŸ”§ FonctionnalitÃ©s AvancÃ©es

### Mode Vision

Les modÃ¨les GPT-5.1 et GPT-5 supportent l'analyse d'images. Uploadez des images dans le chat pour obtenir des descriptions, analyses ou rÃ©ponses contextuelles.

### Gros Fichiers

- Fichiers > `MAX_FILE_MB` traitÃ©s par morceaux (streaming)
- CSV/TSV : lecture par blocs
- Excel : feuille par feuille
- PDF : page par page

### Reranking Intelligent

1. **Cross-Encoder** (MS-MARCO MiniLM L-6) â€” scoring sÃ©mantique prÃ©cis
2. **BM25 Fallback** â€” algorithme lexical si cross-encoder indisponible

---

## ğŸ“¦ DÃ©pendances Principales

- `streamlit` â€” Interface web
- `openai` â€” API OpenAI
- `faiss-cpu` â€” Indexation vectorielle
- `sentence-transformers` â€” Cross-encoder reranking
- `pypdf` â€” Extraction PDF
- `python-docx` â€” Extraction DOCX
- `pandas` / `openpyxl` â€” Traitement tableurs
- `tiktoken` â€” Comptage de tokens
- `rank-bm25` â€” Reranking BM25

---

## ğŸ¨ Personnalisation

- **ModÃ¨les** : Modifiez `AVAILABLE_MODELS` dans `main.py`
- **ThÃ¨me** : Ajustez `.streamlit/config.toml`
- **Prompts** : Ã‰ditez `rag/prompts.py` et `BASE_GLOBAL_SYSTEM_PROMPT`

---

## ğŸ“ Licence

Ce projet est distribuÃ© sous licence [MIT](LICENSE).

---

## ğŸ¤ Contribution

Les contributions sont bienvenues ! Ouvrez une issue ou soumettez une pull request.
